{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alibaba Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('images/train_data.txt', skipinitialspace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.shape, df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_ellipse'].astype(np.float32).plot.hist(title='Ellipses Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['center_x', 'center_y']].plot.hist(bins=50, alpha=0.5, title='Centers Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['angle'].plot.hist(title='Angles Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['axis_1', 'axis_1']].plot.hist(bins=50, alpha=0.5, title='Axis Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(path):\n",
    "    df = pd.read_csv(path, skipinitialspace=True)\n",
    "    images = df.pop('images')\n",
    "    df = df.astype(np.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images.values, df.to_dict('list')))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset('images/train_data.txt')\n",
    "test_dataset = make_dataset('images/test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, d in train_dataset.take(5):\n",
    "    print(f'path={path}: is_ellipse={d[\"is_ellipse\"]}, center_x={d[\"center_x\"]}, center_y={d[\"center_y\"]}, angle={d[\"angle\"]}, axis_1={d[\"axis_1\"]}, axis_2={d[\"axis_2\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, d in test_dataset.take(5):\n",
    "    print(f'path={path}: is_ellipse={d[\"is_ellipse\"]}, center_x={d[\"center_x\"]}, center_y={d[\"center_y\"]}, angle={d[\"angle\"]}, axis_1={d[\"axis_1\"]}, axis_2={d[\"axis_2\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess(path, d):\n",
    "    X = load_img(path)\n",
    "    y = d['is_ellipse']\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def display_data(X, y):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(f'{y[i]:.3f}')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.shuffle(10000).map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False).batch(16).prefetch(AUTOTUNE)\n",
    "test_ds = test_dataset.map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False).batch(16).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in train_ds.take(1):\n",
    "    display_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in test_ds.take(1):\n",
    "    display_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(50, 50, 3)))\n",
    "model.add(layers.Lambda(lambda x: x/255))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=test_ds, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, d):\n",
    "    X = load_img(path)\n",
    "    is_ellipse = d['is_ellipse']\n",
    "    center_x = d[\"center_x\"]\n",
    "    center_y = d[\"center_y\"]\n",
    "    angle = d[\"angle\"]\n",
    "    axis_1 = d[\"axis_1\"]\n",
    "    axis_2 = d[\"axis_2\"]\n",
    "    angle = tf.where(angle >= 180, 360-angle, angle)\n",
    "    angle = tf.where(angle == 180, 0., angle)\n",
    "    angle = tf.where(tf.abs(axis_1-axis_2) == 0, 0., angle)\n",
    "    angle = tf.one_hot(tf.cast(angle, tf.int32), 179)\n",
    "    center_x /= 50\n",
    "    center_y /= 50\n",
    "    axis_1 /= 25\n",
    "    axis_2 /= 25\n",
    "    y = tf.stack([is_ellipse, center_x, center_y, axis_1, axis_2], axis=-1)\n",
    "    y = tf.concat([y, angle], axis=-1)\n",
    "    X = tf.cast(X, tf.float32) / 127.5 - 1.0\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.shuffle(10000).map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False).batch(128).prefetch(AUTOTUNE)\n",
    "test_ds = test_dataset.map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False).batch(16).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in test_ds.take(1):\n",
    "    print(X.shape, y.shape)\n",
    "    print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    is_ellipse_loss = losses.binary_crossentropy(y_true[...,0:1], y_pred[...,0:1])\n",
    "    is_ellipse_loss = tf.reduce_mean(is_ellipse_loss)\n",
    "    \n",
    "    is_ellipse = y_true[...,0]\n",
    "    \n",
    "    centers_loss = losses.logcosh(y_true[...,1:3], y_pred[...,1:3])*is_ellipse\n",
    "    centers_loss = 10.0 * tf.reduce_mean(centers_loss)        \n",
    "    \n",
    "    axis_loss = losses.logcosh(y_true[...,3:5], y_pred[...,3:5])*is_ellipse\n",
    "    axis_loss = 10.0 * tf.reduce_mean(axis_loss)            \n",
    "    \n",
    "    #angle_loss = losses.categorical_crossentropy(y_true[...,6:], y_pred[...,6:])*is_ellipse\n",
    "    angle_loss = tf.abs(tf.argmax(y_true[...,6:])-tf.argmax(y_pred[...,6:]))\n",
    "    angle_loss = tf.cast(angle_loss, tf.float32)\n",
    "    angle_loss = 1./ 180 * tf.reduce_mean(angle_loss)\n",
    "    \n",
    "    #tf.print(is_ellipse_loss, angle_loss, centers_loss, axis_loss)\n",
    "\n",
    "    return is_ellipse_loss + angle_loss + centers_loss + axis_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "# x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "# x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "# x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "# backbone = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(50, 50, 3))\n",
    "# x = backbone(x_in)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# is_ellipse = layers.Dense(1, activation='sigmoid')(x)\n",
    "# angle = layers.Dense(1, activation=None)(x)\n",
    "# centers = layers.Dense(2, activation=None)(x)\n",
    "# axis = layers.Dense(2, activation=None)(x)\n",
    "\n",
    "backbone =tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(50, 50, 3))\n",
    "\n",
    "x = backbone.output\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "is_ellipse = layers.Dense(1, activation='sigmoid')(x)\n",
    "centers = layers.Dense(2, activation='sigmoid')(x)\n",
    "axis = layers.Dense(2, activation='sigmoid')(x)\n",
    "angle= layers.Dense(179, activation='softmax')(x)\n",
    "\n",
    "x = tf.concat([is_ellipse, angle, centers, axis], axis=-1)\n",
    "\n",
    "# create the new model\n",
    "model = tf.keras.Model(inputs=backbone.input, outputs=x)\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss=custom_loss, optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cp = tf.keras.callbacks.ModelCheckpoint('checkpoints/cp.ckpt', save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True, verbose=1)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=100, callbacks=[model_cp, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step - loss: 0.7220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7220373153686523"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('checkpoints/cp.ckpt')\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = test_dataset.map(preprocess).batch(1)\n",
    "\n",
    "results = [(y[0].numpy(),model(X)[0].numpy()) for X, y in val_ds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ellipse Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [y[0] for y,p in results]\n",
    "y_pred = [p[0] > 0.5 for y,p in results]\n",
    "    \n",
    "score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angle Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 45.21313327353202\n",
      "\n",
      "y=118.80000472068787, p=51.0269558429718\n",
      "y=90.0, p=10.213660150766373\n",
      "y=100.80000042915344, p=68.95139694213867\n",
      "y=100.80000042915344, p=60.931795835494995\n",
      "y=64.80000257492065, p=47.31012761592865\n",
      "y=57.59999871253967, p=48.16783368587494\n",
      "y=61.200000643730164, p=0.15837416402064264\n",
      "y=115.19999742507935, p=79.83592987060547\n",
      "y=82.80000150203705, p=58.416441679000854\n",
      "y=93.59999656677246, p=22.52397358417511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [y[1]*180 for y,p in results if y[0] == 1]\n",
    "y_pred = [p[1]*180 for y,p in results if y[0] == 1]\n",
    "\n",
    "error = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f'Error: {error}\\n')\n",
    "\n",
    "for y,p in list(zip(y_true, y_pred))[:10]:\n",
    "    print(f'y={y}, p={p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centers Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 15.733471870422363\n",
      "\n",
      "y=[30. 26.], p=[10. 12.]\n",
      "y=[31. 40.], p=[10. 17.]\n",
      "y=[29. 12.], p=[19.  7.]\n",
      "y=[24. 14.], p=[14.  5.]\n",
      "y=[24. 18.], p=[20.  9.]\n",
      "y=[16. 18.], p=[13. 10.]\n",
      "y=[28. 46.], p=[ 6. 19.]\n",
      "y=[24. 30.], p=[14. 10.]\n",
      "y=[30.  8.], p=[25.  5.]\n",
      "y=[31. 30.], p=[13. 16.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = [y[2:4]*50 for y,p in results if y[0] == 1]\n",
    "y_pred = [np.round(p[2:4]*50) for y,p in results if y[0] == 1]\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(f'Error: {error}\\n')\n",
    "\n",
    "for y,p in list(zip(y_true, y_pred))[:10]:\n",
    "    print(f'y={y}, p={p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 7.824385643005371\n",
      "\n",
      "[24.  0.], [6.503 0.   ]\n",
      "[20. 25.], [10.132  0.   ]\n",
      "[10.  0.], [2.649 0.   ]\n",
      "[13.  0.], [7.215 0.   ]\n",
      "[3. 0.], [3.96 0.  ]\n",
      "[5. 0.], [6.766 0.   ]\n",
      "[23. 25.], [12.748  0.   ]\n",
      "[3. 0.], [1.849 0.   ]\n",
      "[7. 0.], [1.723 0.   ]\n",
      "[22.  0.], [7.296 0.   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = [y[4:6]*25 for y,p in results if y[0] == 1]\n",
    "y_pred = [np.abs(p[4:6])*25 for y,p in results if y[0] == 1]\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(f'Error: {error}\\n')\n",
    "\n",
    "for y,p in list(zip(y_true, y_pred))[:10]:\n",
    "    print(f'{y}, {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
